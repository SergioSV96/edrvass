{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procesamiento\n",
    "Vamos a utilizar sklearn para el procesamiento de datos mediante pipelines.\n",
    "- Buena info de cómo hacer esto aquí: https://www.youtube.com/watch?v=0B5eIE_1vpU&t=1227s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "train = pd.read_csv('../data/train_data.csv')\n",
    "test = pd.read_csv('../data/test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a definir los datos de entrenamiento\n",
    "X = train.drop(['mineralType', 'id'], axis=1)\n",
    "y = train['mineralType']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sklearn pipeline for data preprocessing\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer, OneHotEncoder, OrdinalEncoder, StandardScaler, RobustScaler\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, IterativeImputer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, make_scorer, recall_score, precision_score\n",
    "from sklearn.decomposition import PCA, NMF\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn import set_config\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import math\n",
    "from joblib import Memory\n",
    "from shutil import rmtree\n",
    "\n",
    "mlflow.sklearn.autolog()\n",
    "mlflow.set_experiment(\"knnclassifier\")\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "        # (name, transformer, columns)\n",
    "        (\"temperatureFirstHalfPlanetRotation\", make_pipeline(IterativeImputer(missing_values=-999.0), FunctionTransformer(lambda f: (f - 32) / 1.8, feature_names_out=\"one-to-one\"), RobustScaler()), ['temperatureFirstHalfPlanetRotation']), # convert from Fahrenheit to Celsius\n",
    "        (\"temperatureSecondHalfPlanetRotation\", StandardScaler(), ['temperatureSecondHalfPlanetRotation']), # pass through the column unchanged\n",
    "        (\"waterStreamDistanceX\", make_pipeline(FunctionTransformer(lambda f: f * 0.3048, feature_names_out=\"one-to-one\"), StandardScaler()), ['waterStreamDistanceX']), # convert from feet to meters\n",
    "        (\"waterStreamDistanceY\", StandardScaler(), ['waterStreamDistanceY']), # pass through the column unchanged\n",
    "        (\"planetSection\", OneHotEncoder(handle_unknown = \"ignore\"), ['planetSection']), # one-hot encode the planetSection column\n",
    "        (\"cover\", OneHotEncoder(handle_unknown='error', drop='first'), ['cover']), # one-hot encode the cover column and drop the first column (the one with the missing values == 0)\n",
    "        (\"climaticZone\", OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1), ['climaticZone']), # ordinal encode the climaticZone column TODO: drop category 3? what to do? only one row has a 3\n",
    "        (\"geoZone\", OneHotEncoder(handle_unknown = \"ignore\"), ['geoZone']), # one-hot encode the geoZone column TODO: drop category 5?\n",
    "        (\"rockSize\", OneHotEncoder(handle_unknown='ignore', drop='first'), ['rockSize']), # one-hot encode the rockSize column and drop the first column (the one with the missing values == 0)\n",
    "        (\"magmaConcentrationDistance\", OneHotEncoder(handle_unknown = \"ignore\"), ['magmaConcentrationDistance']), # one-hot encode the rockSize column and drop the first column (the one with the missing values == 0) TODO: use Ordinal Encoder?\n",
    "        (\"mineralDensity\", make_pipeline(IterativeImputer(missing_values=-999.0), RobustScaler()), ['mineralDensity']), # pass through the column unchanged\n",
    "        (\"detectionDepth\", StandardScaler(), ['detectionDepth']), # pass through the column unchanged TODO: convert km to m?\n",
    "        (\"longitude\", StandardScaler(), ['longitude']), # pass through the column unchanged TODO: values > 360? do x - 360\n",
    "    ],\n",
    "    verbose_feature_names_out=False, remainder='passthrough'\n",
    ")\n",
    "\n",
    "def euclidean_distance(x, y):\n",
    "    res = []\n",
    "    for i in range(len(x)):\n",
    "        res.append(math.sqrt(x[i]**2 + y[i]**2))\n",
    "    return np.array(res)\n",
    "\n",
    "class CreateVariables(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y = None):\n",
    "        # waterSteamDistance\n",
    "        waterStreamDistanceX = X[:,2]\n",
    "        waterStreamDistanceY = X[:,3]\n",
    "        waterStreamDistance = euclidean_distance(waterStreamDistanceX, waterStreamDistanceY)\n",
    "        X = np.append(X, waterStreamDistance.reshape(-1, 1), axis=1)\n",
    "\n",
    "        # temperature (both planet rotations)\n",
    "        temperatureFirstHalfPlanetRotation = X[:,0]\n",
    "        temperatureSecondHalfPlanetRotation = X[:,1]\n",
    "        meanTemperature = (temperatureFirstHalfPlanetRotation + temperatureSecondHalfPlanetRotation)/2\n",
    "        X = np.append(X, meanTemperature.reshape(-1, 1), axis=1)\n",
    "\n",
    "        return X\n",
    "\n",
    "# model = MLPClassifier(random_state=1, max_iter=300)\n",
    "model = KNeighborsClassifier()\n",
    "# model = RandomForestClassifier(bootstrap=False, max_features=5, min_samples_leaf=15,\n",
    "#                          n_estimators=512, n_jobs=-1, random_state=1,\n",
    "#                          warm_start=True)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('create_variables', CreateVariables()),\n",
    "    ('pca', PCA()),\n",
    "    ('model', 'passthrough')\n",
    "])\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        # 'preprocessor__temperatureFirstHalfPlanetRotation__robustscaler': [StandardScaler(), RobustScaler()],\n",
    "        'pca__n_components': [None],\n",
    "        'model': [KNeighborsClassifier()],\n",
    "        'model__n_neighbors': [7],\n",
    "        'model__weights': ['distance'],\n",
    "        'model__metric': ['manhattan'],\n",
    "    },\n",
    "    # {\n",
    "    #     # 'preprocessor__temperatureFirstHalfPlanetRotation__robustscaler': [StandardScaler(), RobustScaler()],\n",
    "    #     'pca__n_components': [None],\n",
    "    #     'model': [GradientBoostingClassifier()],\n",
    "    # },\n",
    "]\n",
    "\n",
    "grid = GridSearchCV(pipe, cv=5, scoring=['accuracy', 'precision_macro'], error_score='raise', return_train_score=True, n_jobs=-1, verbose=4, refit='accuracy',\n",
    "        param_grid=param_grid\n",
    "        )\n",
    "\n",
    "# Train the model\n",
    "grid.fit(X, y)\n",
    "\n",
    "set_config(display='diagram')\n",
    "# grid.get_para ms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results of the grid search to see which parameters are the best for the model to use\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 6))\n",
    "# Sort grid results by ranking\n",
    "grid_results_df = pd.DataFrame(grid.cv_results_)\n",
    "grid_results_df.sort_values(by=['rank_test_accuracy'], ascending=False, inplace=True)\n",
    "plt.plot(grid.cv_results_['mean_test_accuracy'], label='mean test accuracy')\n",
    "plt.plot(grid.cv_results_['mean_test_precision_macro'], label='mean test precision macro')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results by ranking\n",
    "grid_results_df.sort_values(by=['rank_test_accuracy'], ascending=True, inplace=True)\n",
    "grid_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_data = preprocessor.fit_transform(X)\n",
    "\n",
    "preprocessed_dataframe = pd.DataFrame(preprocessed_data, columns=preprocessor.get_feature_names_out())\n",
    "preprocessed_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['mineralDensity'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_dataframe['mineralDensity'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['temperatureFirstHalfPlanetRotation'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_dataframe['temperatureFirstHalfPlanetRotation'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_estimator_.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessor = ColumnTransformer([\n",
    "#         # (name, transformer, columns)\n",
    "#         (\"temperatureFirstHalfPlanetRotation\", make_pipeline(IterativeImputer(missing_values=-999.0), FunctionTransformer(lambda f: (f - 32) / 1.8, feature_names_out=\"one-to-one\"), RobustScaler()), ['temperatureFirstHalfPlanetRotation']), # convert from Fahrenheit to Celsius\n",
    "#         (\"temperatureSecondHalfPlanetRotation\", StandardScaler(), ['temperatureSecondHalfPlanetRotation']), # pass through the column unchanged\n",
    "#         (\"waterStreamDistanceX\", make_pipeline(FunctionTransformer(lambda f: f * 0.3048, feature_names_out=\"one-to-one\"), StandardScaler()), ['waterStreamDistanceX']), # convert from feet to meters\n",
    "#         (\"waterStreamDistanceY\", StandardScaler(), ['waterStreamDistanceY']), # pass through the column unchanged\n",
    "#         (\"planetSection\", OneHotEncoder(handle_unknown = \"ignore\"), ['planetSection']), # one-hot encode the planetSection column\n",
    "#         (\"cover\", OneHotEncoder(handle_unknown='error', drop='first'), ['cover']), # one-hot encode the cover column and drop the first column (the one with the missing values == 0)\n",
    "#         (\"climaticZone\", OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1), ['climaticZone']), # ordinal encode the climaticZone column TODO: drop category 3? what to do? only one row has a 3\n",
    "#         (\"geoZone\", OneHotEncoder(handle_unknown = \"ignore\"), ['geoZone']), # one-hot encode the geoZone column TODO: drop category 5?\n",
    "#         (\"rockSize\", OneHotEncoder(handle_unknown='ignore', drop='first'), ['rockSize']), # one-hot encode the rockSize column and drop the first column (the one with the missing values == 0)\n",
    "#         (\"magmaConcentrationDistance\", OneHotEncoder(handle_unknown = \"ignore\"), ['magmaConcentrationDistance']), # one-hot encode the rockSize column and drop the first column (the one with the missing values == 0) TODO: use Ordinal Encoder?\n",
    "#         (\"mineralDensity\", make_pipeline(IterativeImputer(missing_values=-999.0), RobustScaler()), ['mineralDensity']), # pass through the column unchanged\n",
    "#         (\"detectionDepth\", StandardScaler(), ['detectionDepth']), # pass through the column unchanged TODO: convert km to m?\n",
    "#         (\"longitude\", StandardScaler(), ['longitude']), # pass through the column unchanged TODO: values > 360? do x - 360\n",
    "#     ],\n",
    "#     verbose_feature_names_out=False, remainder='passthrough'\n",
    "# )\n",
    "\n",
    "# def euclidean_distance(x, y):\n",
    "#     res = []\n",
    "#     for i in range(len(x)):\n",
    "#         res.append(math.sqrt(x[i]**2 + y[i]**2))\n",
    "#     return np.array(res)\n",
    "\n",
    "# class CreateVariables(BaseEstimator, TransformerMixin):\n",
    "#     def __init__(self):\n",
    "#         pass\n",
    "        \n",
    "#     def fit(self, X, y = None):\n",
    "#         return self\n",
    "\n",
    "#     def transform(self, X, y = None):\n",
    "#         # waterSteamDistance\n",
    "#         waterStreamDistanceX = X[:,2]\n",
    "#         waterStreamDistanceY = X[:,3]\n",
    "#         waterStreamDistance = euclidean_distance(waterStreamDistanceX, waterStreamDistanceY)\n",
    "#         X = np.append(X, waterStreamDistance.reshape(-1, 1), axis=1)\n",
    "\n",
    "#         # temperature (both planet rotations)\n",
    "#         temperatureFirstHalfPlanetRotation = X[:,0]\n",
    "#         temperatureSecondHalfPlanetRotation = X[:,1]\n",
    "#         meanTemperature = (temperatureFirstHalfPlanetRotation + temperatureSecondHalfPlanetRotation)/2\n",
    "#         X = np.append(X, meanTemperature.reshape(-1, 1), axis=1)\n",
    "\n",
    "#         return X\n",
    "\n",
    "# pipe = Pipeline([\n",
    "#     ('preprocessor', preprocessor),\n",
    "#     ('create_variables', CreateVariables()),\n",
    "# ])\n",
    "\n",
    "# preprocessed_data = pipe.fit_transform(X, y)\n",
    "# reduced_data = PCA(n_components=2).fit_transform(preprocessed_data, y)\n",
    "\n",
    "# print(preprocessed_data.shape)\n",
    "# print(reduced_data.shape)\n",
    "\n",
    "# # reduced_data\n",
    "\n",
    "# # # Plot the PCA results in a scatter plot with the color of the mineral density with a legend\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.scatter(reduced_data[:, 0], reduced_data[:, 1], c=y, cmap='viridis')\n",
    "# plt.xlabel('PC1')\n",
    "# plt.ylabel('PC2')\n",
    "# plt.title('PCA of the data')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessor = ColumnTransformer([\n",
    "#         # (name, transformer, columns)\n",
    "#         (\"temperatureFirstHalfPlanetRotation\", make_pipeline(IterativeImputer(missing_values=-999.0), FunctionTransformer(lambda f: (f - 32) / 1.8, feature_names_out=\"one-to-one\"), RobustScaler()), ['temperatureFirstHalfPlanetRotation']), # convert from Fahrenheit to Celsius\n",
    "#         (\"temperatureSecondHalfPlanetRotation\", StandardScaler(), ['temperatureSecondHalfPlanetRotation']), # pass through the column unchanged\n",
    "#         (\"waterStreamDistanceX\", make_pipeline(FunctionTransformer(lambda f: f * 0.3048, feature_names_out=\"one-to-one\"), StandardScaler()), ['waterStreamDistanceX']), # convert from feet to meters\n",
    "#         (\"waterStreamDistanceY\", StandardScaler(), ['waterStreamDistanceY']), # pass through the column unchanged\n",
    "#         (\"planetSection\", OneHotEncoder(handle_unknown = \"ignore\"), ['planetSection']), # one-hot encode the planetSection column\n",
    "#         (\"cover\", OneHotEncoder(handle_unknown='error', drop='first'), ['cover']), # one-hot encode the cover column and drop the first column (the one with the missing values == 0)\n",
    "#         (\"climaticZone\", OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1), ['climaticZone']), # ordinal encode the climaticZone column TODO: drop category 3? what to do? only one row has a 3\n",
    "#         (\"geoZone\", OneHotEncoder(handle_unknown = \"ignore\"), ['geoZone']), # one-hot encode the geoZone column TODO: drop category 5?\n",
    "#         (\"rockSize\", OneHotEncoder(handle_unknown='ignore', drop='first'), ['rockSize']), # one-hot encode the rockSize column and drop the first column (the one with the missing values == 0)\n",
    "#         (\"magmaConcentrationDistance\", OneHotEncoder(handle_unknown = \"ignore\"), ['magmaConcentrationDistance']), # one-hot encode the rockSize column and drop the first column (the one with the missing values == 0) TODO: use Ordinal Encoder?\n",
    "#         (\"mineralDensity\", make_pipeline(IterativeImputer(missing_values=-999.0), RobustScaler()), ['mineralDensity']), # pass through the column unchanged\n",
    "#         (\"detectionDepth\", StandardScaler(), ['detectionDepth']), # pass through the column unchanged TODO: convert km to m?\n",
    "#         (\"longitude\", StandardScaler(), ['longitude']), # pass through the column unchanged TODO: values > 360? do x - 360\n",
    "#     ],\n",
    "#     verbose_feature_names_out=False, remainder='passthrough'\n",
    "# )\n",
    "\n",
    "# def euclidean_distance(x, y):\n",
    "#     res = []\n",
    "#     for i in range(len(x)):\n",
    "#         res.append(math.sqrt(x[i]**2 + y[i]**2))\n",
    "#     return np.array(res)\n",
    "\n",
    "# class CreateVariables(BaseEstimator, TransformerMixin):\n",
    "#     def __init__(self):\n",
    "#         pass\n",
    "        \n",
    "#     def fit(self, X, y = None):\n",
    "#         return self\n",
    "\n",
    "#     def transform(self, X, y = None):\n",
    "#         # waterSteamDistance\n",
    "#         waterStreamDistanceX = X[:,2]\n",
    "#         waterStreamDistanceY = X[:,3]\n",
    "#         waterStreamDistance = euclidean_distance(waterStreamDistanceX, waterStreamDistanceY)\n",
    "#         X = np.append(X, waterStreamDistance.reshape(-1, 1), axis=1)\n",
    "\n",
    "#         # temperature (both planet rotations)\n",
    "#         temperatureFirstHalfPlanetRotation = X[:,0]\n",
    "#         temperatureSecondHalfPlanetRotation = X[:,1]\n",
    "#         meanTemperature = (temperatureFirstHalfPlanetRotation + temperatureSecondHalfPlanetRotation)/2\n",
    "#         X = np.append(X, meanTemperature.reshape(-1, 1), axis=1)\n",
    "\n",
    "#         return X\n",
    "\n",
    "# pipe = Pipeline([\n",
    "#     ('preprocessor', preprocessor),\n",
    "#     ('create_variables', CreateVariables())\n",
    "# ])\n",
    "\n",
    "# preprocessed_data = pipe.fit_transform(X, y)\n",
    "# reduced_data = PCA(n_components=3).fit_transform(preprocessed_data, y)\n",
    "\n",
    "# print(preprocessed_data.shape)\n",
    "# print(reduced_data.shape)\n",
    "\n",
    "# # reduced_data\n",
    "\n",
    "# # Create a dataframe with the reduced data and the labels\n",
    "# reduced_data_df = pd.DataFrame(reduced_data, columns=['PC1', 'PC2', 'PC3'])\n",
    "# reduced_data_df['mineralDensity'] = y\n",
    "\n",
    "# # Create an interactive 3D scatter plot of the PCA results with the color of the mineral density with a legend in plotly express\n",
    "# import plotly.express as px\n",
    "\n",
    "# fig = px.scatter_3d(\n",
    "#     reduced_data_df,\n",
    "#     x='PC1',\n",
    "#     y='PC2',\n",
    "#     z='PC3',\n",
    "#     color='mineralDensity',\n",
    "#     color_continuous_scale=px.colors.sequential.Viridis,\n",
    "#     opacity=0.8,\n",
    "#     title='PCA of the data'\n",
    "# )\n",
    "# fig.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2b432026e43f20cf504aae65236a164c08dc39f216586df0ee869a7227797bc6"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 64-bit ('fase6')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
