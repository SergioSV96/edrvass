{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enunciado\n",
    "## Destino: Planeta VASS!\n",
    "Por fin! El sistema que hemos creado ha terminado de analizar las características del planeta y se ha comprobado que es habitable. Después de un largo trayecto y varios inconvenientes, estamos a un paso de cumplir nuestro objetivo!\n",
    "\n",
    "Este último paso es, probablemente, el más importante de todos, aterrizar en el planeta VASS.\n",
    "Para asegurar el éxito del aterrizaje, hemos realizado una serie de experimentos en un espacio de simulación para predecir la manera más eficiente de aterrizar de forma segura.\n",
    "\n",
    "Sin embargo, el simulador ha tenido problemas a la hora de determinar la eficiencia en algunos de los experimentos, por lo que ahora nuestro objetivo será analizar las simulaciones y determinar el nivel de eficiencia de aterrizaje de cada uno de los experimentos en los que falló. Tendremos que tener en cuenta las siguientes observaciones:\n",
    "\n",
    "### Observaciones\n",
    "- Cada uno de los experimentos cuenta con una serie pasos compuestos de estados y acciones de la nave de una simulación determinada.\n",
    "- En cada paso el simulador genera un estado y decide una acción. El siguiente estado se verá determinado por esta acción, y a su vez se decidirá una nueva acción en base a ese nuevo estado, eso hasta que la simulación llegue a su fin.\n",
    "- En cada paso, el simulador determina la contribución individual que ha tenido la acción tomada a la eficiencia total. Finalmente se calculan todas estas contribuciones para determinar la eficiencia total del experimento.\n",
    "- La eficiencia es una función que utiliza internamente el simulador para determinar cuándo está tomando buenas decisiones. Esta función podría estar teniendo en cuenta los cambios que hay en los estados, así como las distintas acciones y variables.\n",
    "- Las simulaciones se han realizado en diversas condiciones: gravedad, viento y turbulencias.\n",
    "- CUIDADO! En algunas de las simulaciones los valores de la gravedad y viento no se guardaron correctamente, por lo que el sistema las ha registrado con un valor de 0.\n",
    "\n",
    "Descarga los datos de los experimentos, analízalos y crea un modelo para predecir la eficiencia total de cada uno de los experimentos. Por último, observa los experimentos del conjunto de test que viene incluido en la descarga de los datos y envía las predicciones de los registros en el orden original separadas por comas, de la siguiente manera:\n",
    "\n",
    "205.12,122.14,80.34,30.15,109.93\n",
    "\n",
    "El ejemplo expuesto se correspondería con las predicciones de los 5 primeros registros, tendréis que subir en una sola línea las 2,000 predicciones usando este formato."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to land the Star Cruiser 42\n",
    "\n",
    "## Context\n",
    "\n",
    "This dataset contains information about simulations of landing a spaceship in a 2D environment.\n",
    "This information can be used to determine the efficiency function in order to evaluate the best actions possible in a future landing.\n",
    "\n",
    "\n",
    "## Metadata\n",
    "Number of train files: 9513\n",
    "Number of test files: 2000\n",
    "Number of variables: 13\n",
    "Target variable: efficiency\n",
    "\n",
    "\n",
    "File variable details:\n",
    "\n",
    "- x_pos # The position of the ship on the X axis, in units relative to the landing platform.\n",
    "- y_pos # The position of the ship on the Y axis, in units relative to the landing platform.\n",
    "- x_vel # Velocity of the ship on the X axis.\n",
    "- y_vel # Velocity of the ship on the Y axis.\n",
    "- angle # The angle of the spaceship in radians.\n",
    "- ang_vel # The angular velocity of the spaceship.\n",
    "- leg_1 # Boolean that represent whether leg 1 is in contact with the ground or not\n",
    "- leg_2 # Boolean that represent whether leg 2 is in contact with the ground or not\n",
    "- main_booster #  The throttle of the main engine.\n",
    "- lat_booster # The throttle of the lateral boosters.\n",
    "\n",
    "The first 6 variables determine the state and each step, and the last two (main_booster and lat_booster) are the actions taken in response\n",
    "to that state, whose repercussions will be seen in the following step.\n",
    "\n",
    "Experiment variable details:\n",
    "- gravity # The magnitude of the gravity acceleration. A value of 0 means that the system didn't register the real value.\n",
    "- wind_power # The maximum magnitude of linear wind applied to the spaceship. A value of 0 means that the system didn't register the real value.\n",
    "- turbulences # The maximum magnitude of rotational wind applied to the spaceship.\n",
    "\n",
    "Target variable detail\n",
    "- efficiency # An internal function of the simulator to evaluate the quality of the landing.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import kurtosis, skew\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os, os.path\n",
    "import errno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open fase7/data/experiments_summary_test.xlsx and train\n",
    "experiments_summary_test = pd.read_excel('data/experiments_summary_test.xlsx')\n",
    "experiments_summary_train = pd.read_excel('data/experiments_summary_train.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_summary_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_summary_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_summary_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_summary_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_summary = pd.concat([experiments_summary_train, experiments_summary_test], ignore_index=True)\n",
    "experiments_summary.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos con los que vamos a trabajar son experimentos que se componen por series temporales de longitud variable. Para un experimento i, contamos con un conjunto de datos de la forma (t_j, x_j), donde t_j es el timestamp y x_j el vector de variables.\n",
    "\n",
    "Cada experimento i cuenta con:\n",
    "- gravity\n",
    "- wind_power\n",
    "- tubulence_power\n",
    "- eficciency\n",
    "\n",
    "El vector de variables x_j está compuesto por las variables:\n",
    "- x_pos\n",
    "- y_pos\n",
    "- x_vel\n",
    "- y_vel\n",
    "- angle\n",
    "- ang_vel\n",
    "- leg1\n",
    "- leg2\n",
    "- main_booster\n",
    "- lat_booster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in experiments_summary_train.columns[1:]:\n",
    "    fig = plt.figure(figsize=(9, 3))\n",
    "    sns.histplot(data=experiments_summary_train, x=col, kde=True)\n",
    "    plt.show()\n",
    "    fig.clf()\n",
    "\n",
    "    print('Skewness:', skew(experiments_summary_train[col]))\n",
    "    print('Kurtosis:', kurtosis(experiments_summary_train[col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in experiments_summary_test.columns[1:]:\n",
    "    fig = plt.figure(figsize=(9, 3))\n",
    "    sns.histplot(data=experiments_summary_test, x=col, kde=True)\n",
    "    plt.show()\n",
    "    fig.clf()\n",
    "\n",
    "    print('Skewness:', skew(experiments_summary_test[col]))\n",
    "    print('Kurtosis:', kurtosis(experiments_summary_test[col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for q in range(100):\n",
    "    if np.percentile(experiments_summary_train['efficiency'], q) >= 0:\n",
    "        print(q)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9, 3))\n",
    "sns.histplot(data=experiments_summary_train[experiments_summary_train['efficiency'] > 0], x='efficiency', kde=True)\n",
    "plt.show()\n",
    "fig.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for q in range(100):\n",
    "    if np.percentile(experiments_summary_train['efficiency'], q) >= 350:\n",
    "        print(q)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los dos conjuntos siguen la misma distribución para las variables como es de esperar, además de contar con los outliers comentados en el enunciado del ejercicio correspondientes al valor 0 para las variables gravity y wind_power.\n",
    "\n",
    "Para la variable total_timesteps, podemos ver que aunque el 75% de las entradas tiene de un valor aproximadamente menor a 240 existen entradas que se extienden hasta los 900. \n",
    "\n",
    "Para la variable total_timesteps podemos ver que el 75% de las series cuenta con un timestamp menor a 242. El resto de casos se tratan de outliers, es decir, experimentos para los que el aterrizaje ha necesitado más tiempo. Esta variable se trata de una distribución de cola larga sesgada a la derecha.\n",
    "\n",
    "Para las variables gravity y wind_power siguen una distribución uniforme, a excepción de las entradas con valor 0 para estas variables ya que se tratan de valores no registrados por el sistema.\n",
    "\n",
    "Para la variable efficiency se observa una distribución de cola larga muy sesgada a la izquierda. El 3% de las entradas cuenta con un valor negativo para efficiency, por lo que la mayoría de entradas cuentan con un valor positivo para la variable. Además, un 91% de estas se encuentran entre 350 y 425.6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primera toma de contacto\n",
    "Tiene pinta de ser un problema de aprendizaje por refuerzo (reinforcement learning), pero creo que también podría ser un problema de redes neuronales recurrentes.\n",
    "\n",
    "#### Aprendizaje por refuerzo\n",
    "El aprendizaje por refuerzo es una técnica de aprendizaje que consiste en una serie de iteraciones de entrenamiento, donde el objetivo es aprender a predecir el estado siguiente a partir del estado actual. https://es.wikipedia.org/wiki/Aprendizaje_por_refuerzo\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/1/1b/Reinforcement_learning_diagram.svg/250px-Reinforcement_learning_diagram.svg.png \"RL\")\n",
    "\n",
    "\n",
    "Pensandolo mejor, es un problema supervisado, por lo que no creo que sea un problema de aprendizaje por refuerzo, aunque sí parece que el \"simulador\" que genera estos experimentos internamente es una inteligencia artificial de Reinforcement Learning.\n",
    "Nosotros lo que tenemos que hacer es aprender a predecir la valoración de todo el conjunto de acciones de cada experimento.\n",
    "\n",
    "#### Idea de red neuronal recurrente\n",
    "La idea de la red neuronal recurrente es que la red se comporte como una máquina de estados, y que cada vez que se ejecuta una acción, se guarda el estado actual en una matriz de estados, y se guarda la acción que se ha tomado en una matriz de acciones. Podríamos probar con una LSTM.\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/9/93/LSTM_Cell.svg/300px-LSTM_Cell.svg.png \"LSTM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Planteamiento como problema de aprendizaje por refuerzo (reinforcement learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un problema de aprendizaje por refuerzo cuenta con los siguientes elementos:\n",
    "\n",
    "- Estado: Situación del agente. En el problema se representa por las variables:\n",
    "    - x_pos, y_pos\n",
    "    - x_vel, y_vel\n",
    "    - angle, angle_vel\n",
    "    - leg1, leg2\n",
    "\n",
    "- Acciones: Acciones que puede realizar el agente. En el problema se representan por las variables:\n",
    "    - main_booster\n",
    "    - lat_booster\n",
    "\n",
    "\n",
    "- Entorno: Entorno en el que se encuentra el agente. En el problema se representa por las variables:\n",
    "    - gravity\n",
    "    - wind_power\n",
    "    - turbulences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding static fields to time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkdir_p(path):\n",
    "    try:\n",
    "        os.makedirs(path)\n",
    "    except OSError as exc: # Python >2.5\n",
    "        if exc.errno == errno.EEXIST and os.path.isdir(path):\n",
    "            pass\n",
    "        else: raise\n",
    "\n",
    "def safe_open_w(path):\n",
    "    mkdir_p(os.path.dirname(path))\n",
    "    return open(path, 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_series_path = 'data/train'\n",
    "test_series_path = 'data/test'\n",
    "train_experiments_summary_path = 'data/experiments_summary_train.xlsx'\n",
    "test_experiments_summary_path = 'data/experiments_summary_test.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have added the static variables (gravity, wind_power, turbulence_power)\n",
    "# Create a numpy array of shape (samples, timesteps, features) from several csv files and assign each to the target variable (efficiency)\n",
    "# - Load the data from the csv files\n",
    "# - Create a numpy array of shape (samples, timesteps, features)\n",
    "# - Assign each numpy array to a target variable\n",
    "# - Return the target variable\n",
    "def transform_data(series_path, experiments_summary_path, target_variable=None):\n",
    "    experiments_summary = pd.read_excel(experiments_summary_path)\n",
    "    experiments_summary = experiments_summary.set_index('filename')\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "    for filename in os.listdir(series_path):\n",
    "        series_file = os.path.join(series_path, filename)\n",
    "        experiment_series = pd.read_csv(series_file)\n",
    "        \n",
    "        experiment_summary = experiments_summary.loc[filename]\n",
    "        \n",
    "        # Preprocessing steps\n",
    "        # - Add static fields\n",
    "        for static_var in ['gravity', 'wind_power', 'turbulence_power']:\n",
    "            experiment_series[static_var] = np.repeat(experiment_summary[static_var], experiment_summary['total_timesteps']+1)\n",
    "        \n",
    "        X.append(experiment_series.values)\n",
    "\n",
    "        if target_variable is not None:\n",
    "            y.append(experiment_summary[target_variable])\n",
    "    \n",
    "    if target_variable is not None:\n",
    "        return np.array(X), np.array(y)\n",
    "    else:\n",
    "        return np.array(X)\n",
    "\n",
    "train_X, train_y = transform_data(train_series_path, train_experiments_summary_path, 'efficiency')\n",
    "test_X = transform_data(test_series_path, test_experiments_summary_path)\n",
    "\n",
    "# Dump the data to a numpy files\n",
    "np.save('data/train_X.npy', train_X)\n",
    "np.save('data/train_y.npy', train_y)\n",
    "np.save('data/test_X.npy', test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from the numpy files and transform it to (samples, timesteps, features)\n",
    "train_X, train_y = np.load('data/train_X.npy', allow_pickle=True), np.load('data/train_y.npy', allow_pickle=True)\n",
    "test_X = np.load('data/test_X.npy', allow_pickle=True)\n",
    "\n",
    "print(train_X.shape, train_y.shape)\n",
    "print(train_X[0].shape, train_y[0].shape)\n",
    "print(train_X[0], train_y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad the data to make it of the same length (max of all samples)\n",
    "def pad_data(X):\n",
    "    max_length = max([x.shape[0] for x in X])\n",
    "    X_padded = []\n",
    "    for x in X:\n",
    "        x_padded = np.zeros((max_length, x.shape[1]))\n",
    "        x_padded[:x.shape[0], :] = x\n",
    "        X_padded.append(x_padded)\n",
    "    return np.array(X_padded)\n",
    "\n",
    "train_X = pad_data(train_X)\n",
    "test_X = pad_data(test_X)\n",
    "\n",
    "print(train_X.shape, train_y.shape)\n",
    "print(train_X[0].shape, train_y[0].shape)\n",
    "print(test_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_data_lstm(X):\n",
    "    return X.reshape((X.shape[0], X[0].shape[0], X[0].shape[1]))\n",
    "\n",
    "train_X = reshape_data_lstm(train_X)\n",
    "test_X = reshape_data_lstm(test_X)\n",
    "\n",
    "print(train_X.shape, train_y.shape)\n",
    "print(train_X[0].shape, train_y[0].shape)\n",
    "print(test_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling and imputing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crearemos una red LSTM que reciba series temporales asociadas a cada uno de los experimentos. Estas series contarán con todos las variables asociadas al estado y las acciones del agente, además de introducir como nuevas variables las del entorno. Estas últimas tendrán el mismo valor para todos los pasos del experimento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que las distintas series son de longitud variable y se encuentran en distintos archivos csv, deberemos entrenar la red mediante mini batches de tamano 1 (cada uno de los experimentos de los archivos). Otra opción sería realizar padding sobre las series, pero al contar con un rango amplio de timesteps para las series además de contar con gran cantidad de valores atípicos no parece un enfoque adecuado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(16, input_shape=(train_X.shape[1], train_X.shape[2]), return_sequences=False)) # input_shape=(timesteps, features) return_sequences=False -> returns a single vector\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "\n",
    "# Train the model with early stopping.\n",
    "history = model.fit(train_X, train_y, epochs=50, batch_size=32, validation_split=0.2, verbose=2, shuffle=False, callbacks=[EarlyStopping(monitor='val_loss', patience=10, min_delta=0.0001, restore_best_weights=True)])\n",
    "\n",
    "# Plot the model's predictions\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.summary()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2b432026e43f20cf504aae65236a164c08dc39f216586df0ee869a7227797bc6"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 64-bit ('fase6')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
